MODEL:
    ARCHITECTURE: "ALEXNET"
    PRETRAINED_MODEL_PATH: "/home/liubin/HashGAN/models/cifar10_20181119_163535_D_LR_0.0001_G_LR_0.0001_ARCHITECTURE_NORM_PRETRAIN_False_PARTIAL_True_REALFAKE_False_NORMEDTrue_WGAN_SCALE_1.0_ACGAN_SCALE_1.0_ALPHA_5_FAKE_RATIO_1.0/iteration_99999.ckpt"
DATA:
    USE_DATASET: "cifar10"  # "cifar10", "nuswide81", "coco"
    LABEL_DIM: 10
    DB_SIZE: 54000
    TEST_SIZE: 1000
    WIDTH_HEIGHT: 32
    OUTPUT_DIM: 3072 # Number of pixels (32*32*3)
    MAP_R: 54000
    LIST_ROOT: "./data_list/cifar10"
    DATA_ROOT: "./data/cifar10"
    OUTPUT_DIR: "./output/cifar10_finetune"
    IMAGE_DIR: "./output/cifar10_finetune/images"
    MODEL_DIR: "./output/cifar10_finetune/models"
    LOG_DIR: "./output/cifar10_finetune/logs"

TRAIN:
    USE_PRETRAIN: True
    BATCH_SIZE: 128
    ITERS: 10000
    CROSS_ENTROPY_ALPHA: 5
    LR: 1e-4  # Initial learning rate
    G_LR: 0.0  # 1e-4
    DECAY: True  # Whether to decay LR over learning
    N_CRITIC: 1  # Critic steps per generator steps
    SAVE_FREQUENCY: 2000  # How frequently to save model
    ACGAN_SCALE: 1.0
    ACGAN_SCALE_G: 0.0
    WGAN_SCALE: 0.0  
    WGAN_SCALE_G: 0.0
